{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9af1ce-b952-4958-aba0-344bbd4224ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "from utils import (get_model_openAI,get_model_groq,get_openAI_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5fa95-dd08-426b-8337-04035e1ca6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df24366-39f7-478f-ad56-949cbb909ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_model_openAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187b0b4-15a7-43e3-9365-0384a945b69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d74f972-75f7-4aa4-9018-5c16a483c3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(\"Hello\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3025f34-148f-459b-be9f-8de29a30e0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "674925fa-7ce3-4b6f-8ece-b190ee36ed8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])  # This is not recommended instead use HumanMessage; SystemMessage\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df484b-2784-4eb3-ae2a-7752141bdc19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "225d9e26-3af7-4a81-8c72-d8b8503892bc",
   "metadata": {},
   "source": [
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b23cb3ab-4ed9-4699-8907-11b34c93b3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Karnataka is Bangalore (officially known as Bengaluru).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"What is the capital Karnataka\"\n",
    "llm.invoke(input).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661415c-2544-4165-b170-966637a7679d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4236dff-1018-4552-b284-e0b9fb42256a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Karnataka is Bangalore (also known as Bengaluru).'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = \"Karnataka\"\n",
    "\n",
    "input = f\"What is the Capital of {state}\"\n",
    "llm.invoke(input).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7387353-38f9-48fd-bcca-3951634525cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5c3ff68-f2e1-4ad3-9177-f16f69ab44c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Karnataka=Bengaluru\\nTamil Nadu=Chennai'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state1 = \"Karnataka\"\n",
    "state2 = \"Tamil Nadhu\"\n",
    "\n",
    "input = f\"What is the Capital of {state1} and {state2}, write in the format of State=Capital with one below other\"\n",
    "llm.invoke(input).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e26619-6d91-474e-8fcc-6d78c95f7575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bba8fe0-fdf8-4b73-bab6-9fd69b363bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Karnataka is Bangalore (also known as Bengaluru).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Initialize the chat model\n",
    "chat  = get_model_openAI(model=\"gpt-4\")\n",
    "\n",
    "# Create a HumanMessage\n",
    "message = HumanMessage(content=\"What is the Capital of Karnataka.\")\n",
    "\n",
    "# Invoke the model with the message\n",
    "response = chat.invoke([message])\n",
    "\n",
    "# Print the response\n",
    "print(response.content)\n",
    "\n",
    "\n",
    "    # Why Use HumanMessage?\n",
    "    # It mimics a real chat interface.\n",
    "    # Useful for multi-turn conversations.\n",
    "    # You can also use SystemMessage and AIMessage for more control over the dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad2628-b9b3-42cd-84fb-8f4042dc803e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f723a2f-631e-4568-a78a-753b22d8e0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to!\n",
      "\n",
      "Quantum computing is a type of computing technology that uses the principles of quantum mechanics. Instead of using bits like traditional computers (which are either a 0 or a 1), quantum computers use quantum bits or \"qubits.\" \n",
      "\n",
      "Qubits can be in many states at once, thanks to a property called superposition. This allows quantum computers to process a high number of possibilities simultaneously. \n",
      "\n",
      "Another key principle is entanglement, where the state of one qubit can depend on the state of another, no matter the distance between them. This interconnectivity can significantly speed up computations.\n",
      "\n",
      "In essence, quantum computing has the potential to solve complex problems much more efficiently than traditional computing. However, it's currently in the early stages of development and faces many challenges, including maintaining qubit stability and managing errors.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "# Initialize the chat model\n",
    "chat  = get_model_openAI(model=\"gpt-4\")\n",
    "\n",
    "# Define a system message to guide the assistant's behavior\n",
    "system_message = SystemMessage(content=\"You are a helpful assistant that writes in a friendly and concise tone.\")\n",
    "\n",
    "# Define a human message (user input)\n",
    "human_message = HumanMessage(content=\"Can you explain what quantum computing is?\")\n",
    "\n",
    "# Send both messages to the model\n",
    "response = chat.invoke([system_message, human_message])\n",
    "\n",
    "# Print the model's response\n",
    "print(response.content)\n",
    "\n",
    "\n",
    "    # What’s Happening:\n",
    "    # SystemMessage sets the persona or behavior of the assistant.\n",
    "    # HumanMessage is the actual user input.\n",
    "    # The model uses both to generate a context-aware response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6316470-7d0e-4101-9461-842cbbd775ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2e352-ffcd-4c28-a97a-73201941593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Initialize the chat model\n",
    "chat  = get_model_openAI(model=\"gpt-4\")\n",
    "\n",
    "# Create a conversation history\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that answers questions clearly.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "    AIMessage(content=\"The capital of France is Paris.\"),\n",
    "    HumanMessage(content=\"Can you also tell me its population?\")\n",
    "]\n",
    "\n",
    "# Invoke the model with the full message history\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "# Print the model's response\n",
    "print(response.content)\n",
    "\n",
    "    ## What is Happening\n",
    "    # It(AIMessage) helps simulate multi-turn conversations.\n",
    "    # Useful when you want to maintain context or test how the model responds to a specific dialogue flow.\n",
    "    \n",
    "    # HumanMessage (for user input)\n",
    "    # SystemMessage (for system instructions)\n",
    "    # AIMessage (for previous AI responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada2395-5b64-4250-bc39-da47d8a44a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8faf3f18-7e99-4a1a-8bbc-fcd2a21e9946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karnataka=Bengaluru\n",
      "Tamil Nadu=Chennai\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "input = f\"What is the Capital of {state1} and {state2}, write in the format of State=Capital with one below other\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[state1,state2],\n",
    "    template = input,\n",
    ")\n",
    "\n",
    "# Format the prompt with actual values\n",
    "formatted_prompt = prompt.format(\n",
    "    state1=\"Karnataka\",\n",
    "    state2=\"Tamil Nadhu\"\n",
    ")\n",
    "\n",
    "llm = get_model_openAI(model=\"gpt-4\")\n",
    "\n",
    "# Step 4: Directly invoke the LLM with the formatted prompt\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# Step 5: Print the result\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a763d-f058-461a-bbc6-86ad0b37fe04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a851c302-c86e-4abb-8ecd-09fa254d1414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Kannada, good morning is said as \"ಶುಭೋದಯ\" (Shubhodaya).\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OpenAI chat model\n",
    "open_ai = get_model_openAI(model = \"gpt-3.5-turbo\")\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "# LLMChain\n",
    "formatted_prompt = PromptTemplate(\n",
    "    input_variables=[\"language\"],\n",
    "    template=\"How do you say good morning in {language}\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(formatted_prompt.format(language = \"Kannada\"))\n",
    "\n",
    "# Step 5: Print the result\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd18193-cbfd-4f4f-bb82-559689a1f587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
