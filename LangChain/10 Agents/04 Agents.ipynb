{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e284d-2133-4799-9525-1ad231721d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ## Core Components of an LLM Agent\n",
    "\n",
    "# ### 1.  `LLM (Language Model)`\n",
    "\n",
    "#      -   The brain of the agent.\n",
    "#      -   Used for reasoning, decision-making, and generating responses.\n",
    "\n",
    "# ### 2.  `Tools (or Functions)`\n",
    "\n",
    "#      -   External capabilities the agent can use to perform actions.\n",
    "#      -   Examples: web search, code execution, file reading, database querying.\n",
    "\n",
    "# ### 3.  `Memory`\n",
    "\n",
    "#      -   Stores past interactions, facts, or context.\n",
    "#      -   Types:\n",
    "#          -   `Short-term memory`: Current conversation or task context.\n",
    "#          -   `Long-term memory`: Persistent knowledge across sessions.\n",
    "\n",
    "# ### 4.  `Planner / Reasoning Engine`\n",
    "\n",
    "#      -   Breaks down complex tasks into smaller steps.\n",
    "#      -   Decides  `what to do next`  based on goals and available tools.\n",
    "#      -   May use techniques like  `chain-of-thought`,  `reflection`, or  `recursive planning`.\n",
    "\n",
    "# ### 5.  `Tool Selector / Router`\n",
    "\n",
    "#      -   Matches the current task or intent to the right tool.\n",
    "#      -   Can be rule-based, LLM-driven, or classifier-based.\n",
    "\n",
    "# ### 6.  `Execution Engine`\n",
    "\n",
    "#      -   Actually runs the selected tool or function.\n",
    "#      -   Handles input/output formatting, error handling, and retries.\n",
    "\n",
    "# ### 7.  `Prompt Templates / Context Builders`\n",
    "\n",
    "#      -   Prepares structured prompts for the LLM.\n",
    "#      -   Injects relevant context, memory, and tool outputs into the prompt.\n",
    "\n",
    "# ### 8.  `Environment / World Model (optional)`\n",
    "\n",
    "#      -   Represents the agent’s understanding of the external world or task state.\n",
    "#      -   Useful in simulations, games, or multi-agent systems.\n",
    "\n",
    "\n",
    "# ### 9.  `Goal or Task Manager`\n",
    "\n",
    "#      -   Tracks the user’s objective or the agent’s mission.\n",
    "#      -   Ensures actions are aligned with the end goal.\n",
    "\n",
    "# ### 10.  `Logging and Feedback Loop`\n",
    "\n",
    "#      -   Tracks tool usage, success/failure, and user feedback.\n",
    "#      -   Helps improve future decisions and tool selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae62f87-2c09-4877-b2ee-43e94d85c101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d89732-cdb0-446b-a90b-b2b0bf3be023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "from utils import (\n",
    "            get_model_openAI,\n",
    "            get_model_groq,\n",
    "            get_openAI_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab9f69-5a4b-4558-9414-941fb68a2b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee9d42e-2eef-4e94-b902-cd10fcb1b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_model_openAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cdf92f-4c11-49a4-9db4-638d72b85063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229bb0a3-6b76-4686-a768-8fa7c558da16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI don't have the current information about the latest advancements in quantum computing. I should use the DuckDuckGo search tool.\n",
      "Action: duckduckgo_search\n",
      "Action Input: Latest advancements in quantum computing\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mModular, scalable hardware architecture for a quantum computer A new quantum-system-on-chip enables the efficient control of a large array of qubits, moving toward practical quantum computing. Explore the latest advancements in quantum computing, sensing, and communication with our comprehensive Quantum Technology Monitor 2025. Today, we're announcing rapid advancements on the path to useful quantum computing: Majorana 1: the world's first Quantum Processing Unit (QPU) powered by a Topological Core, designed to scale to a million qubits on a single chip. Latest Developments in Quantum Computing in 2025 A conceptual visualization of a quantum processor representing the rapid advancements in quantum computing technology in 2025. Quantum computing is set to demonstrate its value in 2025. Learn about the key breakthroughs in quantum hardware, post-quantum cryptography, machine learning, materials, hybrid algorithms, optimisation, and chemistry. This article covers the latest developments in quantum computing and its potential impact on various fields.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the search results, there are several recent advancements in quantum computing. These include the development of a new quantum-system-on-chip that allows for efficient control of a large array of qubits, the announcement of Majorana 1, the world's first Quantum Processing Unit (QPU) powered by a Topological Core that can scale to a million qubits on a single chip, and various breakthroughs in quantum hardware, post-quantum cryptography, machine learning, materials, hybrid algorithms, optimisation, and chemistry.\n",
      "Final Answer: The latest advancements in quantum computing include the creation of a new quantum-system-on-chip for efficient control of qubits, the announcement of Majorana 1 (the world's first QPU powered by a Topological Core), and breakthroughs in areas like quantum hardware, post-quantum cryptography, machine learning, materials, hybrid algorithms, optimisation, and chemistry.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### Multi Agent Collaboration\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Tool for Agent A (Researcher)\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# Agent A: Researcher\n",
    "research_agent = initialize_agent(\n",
    "    tools=[search_tool],\n",
    "    llm=get_model_openAI(model=\"gpt-4\"),\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True)\n",
    "\n",
    "# Agent B: Writer\n",
    "def summarize_research(input_text: str) -> str:\n",
    "    llm = get_model_openAI(model=\"gpt-4\")\n",
    "    return llm.invoke(f\"Summarize this research: {input_text}\").content\n",
    "\n",
    "# Workflow: Multi-Agent Collaboration\n",
    "def multi_agent_workflow(query: str):\n",
    "    research = research_agent.run(query)\n",
    "    summary = summarize_research(research)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "result = multi_agent_workflow(\"Latest advancements in quantum computing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49057de-7a59-4c0c-8ac0-5a286871ed26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
