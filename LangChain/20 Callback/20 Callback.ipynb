{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3ab173-59c9-4caa-adf3-49e333a13ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "from utils import (get_model_openAI,get_model_groq,get_openAI_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2f812-dfd8-4676-823d-3fe1ad3774cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbd6bd9-51e0-4c96-9d25-dc959a4cdcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = read_json(\"keys.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dec989-614b-4d3e-991d-7e0315fc75c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc6f620-ed19-4bce-ab6d-f3602f36a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI chat model\n",
    "llm = get_model_openAI(model = \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27be37-811d-4cfb-8dc1-1e5ee6d41095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4adb5d7b-0e44-44b8-9dd0-a5f2005fc1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is starting...\n",
      "LLM has finished.\n"
     ]
    }
   ],
   "source": [
    "# You use the callbacks parameter when calling a chain or LLM. This is useful for logging, streaming, tracing, or custom behavior during execution.\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "# Step 1: Define a custom callback handler\n",
    "class MyCustomCallbackHandler(BaseCallbackHandler):\n",
    "    def on_llm_start(self, *args, **kwargs):\n",
    "        print(\"LLM is starting...\")\n",
    "\n",
    "    def on_llm_end(self, *args, **kwargs):\n",
    "        print(\"LLM has finished.\")\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        print(f\"New token: {token}\")\n",
    "\n",
    "# Step 2: Create the LLM and chain\n",
    "# llm = OpenAI(openai_api_key=\"your-api-key\", streaming=True)\n",
    "\n",
    "llm = get_model_openAI(model=\"gpt-4\")\n",
    "prompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Step 3: Run the chain with callbacks passed at runtime\n",
    "response = chain.run({\"topic\": \"AI\"}, callbacks=[MyCustomCallbackHandler()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4673269-75c8-47ab-929a-3fc67c46d980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2ae27-1eef-4ef6-b4b1-6f0da165937f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2fe53-53a7-4542-a731-3b4d50ddc32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d73ce5-2adf-4341-a5ce-bd759090fb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adec1da-b22a-478b-972c-968bbd822377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcaed9-f98e-4995-8643-98847ce99b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b8829-102b-4ba6-8c10-698e77108fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
