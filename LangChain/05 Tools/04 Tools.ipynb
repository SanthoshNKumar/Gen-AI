{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d5347c-b6c2-483c-af40-3935d24b7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In LangChain, tools are functionalities that extend the capabilities of an agent or language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "115d99d5-c771-4b6c-813f-675e200dbd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools in LangChain are interfaces that allow an LLM model to interact with external systems, retrieve data, or perform actions \n",
    "# beyond simple text generation. \n",
    "\n",
    "# Types of LangChain Tools\n",
    "    # Search Tools\n",
    "    # Database Query Tools\n",
    "    # API Call Tools\n",
    "    # Mathematical Tools \n",
    "    # File Processing Tools\n",
    "    # Code Execution Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3dd16-3ad7-4c56-86c9-ead566bb8d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59514ea-7940-4e24-920e-877778660ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Types of Tools in LLM Ecosystems\n",
    "\n",
    "# ### 1.  `Information Retrieval Tools`\n",
    "\n",
    "# -   `Purpose`: Fetch real-time or external data.\n",
    "# -   `Examples`:\n",
    "#     -   Web search\n",
    "#     -   Document retrievers (e.g., vector databases like FAISS, Pinecone)\n",
    "#     -   API connectors (e.g., weather, news, finance)\n",
    "\n",
    "# ## Types of Tools in LLM Ecosystems\n",
    "\n",
    "# ### 1.  `Information Retrieval Tools`\n",
    "\n",
    "# -   `Purpose`: Fetch real-time or external data.\n",
    "# -   `Examples`:\n",
    "#     -   Web search\n",
    "#     -   Document retrievers (e.g., vector databases like FAISS, Pinecone)\n",
    "#     -   API connectors (e.g., weather, news, finance)\n",
    "\n",
    "\n",
    "# ### 2.  `Computation Tools`\n",
    "\n",
    "# -   `Purpose`: Perform calculations, data analysis, or code execution.\n",
    "# -   `Examples`:\n",
    "#     -   Python code interpreter\n",
    "#     -   Math solvers (symbolic or numeric)\n",
    "#     -   Spreadsheet processors\n",
    "\n",
    "\n",
    "# ### 3.  `Data Visualization Tools`\n",
    "\n",
    "# -   `Purpose`: Generate charts, graphs, or visual summaries.\n",
    "# -   `Examples`:\n",
    "#     -   Matplotlib/Seaborn-based plotters\n",
    "#     -   Diagram generators (e.g., Mermaid, Graphviz)\n",
    "#     -   Dashboards or report builders\n",
    "\n",
    "\n",
    "# ### 4.  `File and Document Tools`\n",
    "\n",
    "# -   `Purpose`: Read, write, summarize, or transform files.\n",
    "# -   `Examples`:\n",
    "#     -   PDF/Word/Excel readers\n",
    "#     -   File converters (e.g., CSV to JSON)\n",
    "#     -   Document summarizers or extractors\n",
    "\n",
    "\n",
    "# ### 5.  `Language and Text Tools`\n",
    "\n",
    "# -   `Purpose`: Transform or analyze text.\n",
    "# -   `Examples`:\n",
    "#     -   Translators\n",
    "#     -   Sentiment analyzers\n",
    "#     -   Grammar checkers\n",
    "#     -   Text summarizers\n",
    "\n",
    "\n",
    "# ### 6.  `Image and Media Tools`\n",
    "\n",
    "# -   `Purpose`: Generate or analyze visual content.\n",
    "# -   `Examples`:\n",
    "#     -   Image generators (e.g., DALL·E)\n",
    "#     -   OCR (optical character recognition)\n",
    "#     -   Audio transcription or synthesis\n",
    "\n",
    "\n",
    "# ### 7.  `Workflow and Automation Tools`\n",
    "\n",
    "# -   `Purpose`: Automate multi-step tasks or integrate with other systems.\n",
    "# -   `Examples`:\n",
    "#     -   Email or calendar automation\n",
    "#     -   Task management (e.g., Todoist, Notion)\n",
    "#     -   Zapier or Make integrations\n",
    "\n",
    "\n",
    "# ### 8.  `Custom Domain-Specific Tools`\n",
    "\n",
    "# -   `Purpose`: Handle specialized tasks in specific industries.\n",
    "# -   `Examples`:\n",
    "#     -   Legal clause analyzers\n",
    "#     -   Medical symptom checkers\n",
    "#     -   Financial risk calculators\n",
    "\n",
    "\n",
    "# ### 9.  `Security and Access Tools`\n",
    "\n",
    "# -   `Purpose`: Manage authentication, authorization, and secure data access.\n",
    "# -   `Examples`:\n",
    "#     -   OAuth-based access control\n",
    "#     -   Role-based data filters\n",
    "#     -   Audit loggers\n",
    "\n",
    "# ### 2.  `Computation Tools`\n",
    "\n",
    "# -   `Purpose`: Perform calculations, data analysis, or code execution.\n",
    "# -   `Examples`:\n",
    "#     -   Python code interpreter\n",
    "#     -   Math solvers (symbolic or numeric)\n",
    "#     -   Spreadsheet processors\n",
    "\n",
    "# ### 3.  `Data Visualization Tools`\n",
    "\n",
    "# -   `Purpose`: Generate charts, graphs, or visual summaries.\n",
    "# -   `Examples`:\n",
    "#     -   Matplotlib/Seaborn-based plotters\n",
    "#     -   Diagram generators (e.g., Mermaid, Graphviz)\n",
    "#     -   Dashboards or report builders\n",
    "\n",
    "# ### 4.  `File and Document Tools`\n",
    "\n",
    "# -   `Purpose`: Read, write, summarize, or transform files.\n",
    "# -   `Examples`:\n",
    "#     -   PDF/Word/Excel readers\n",
    "#     -   File converters (e.g., CSV to JSON)\n",
    "#     -   Document summarizers or extractors\n",
    "\n",
    "# ### 5.  `Language and Text Tools`\n",
    "\n",
    "# -   `Purpose`: Transform or analyze text.\n",
    "# -   `Examples`:\n",
    "#     -   Translators\n",
    "#     -   Sentiment analyzers\n",
    "#     -   Grammar checkers\n",
    "#     -   Text summarizer\n",
    "\n",
    "# ### 6.  `Image and Media Tools`\n",
    "\n",
    "# -   `Purpose`: Generate or analyze visual content.\n",
    "# -   `Examples`:\n",
    "#     -   Image generators (e.g., DALL·E)\n",
    "#     -   OCR (optical character recognition)\n",
    "#     -   Audio transcription or synthesis\n",
    "\n",
    "# ### 7.  `Workflow and Automation Tools`\n",
    "\n",
    "# -   `Purpose`: Automate multi-step tasks or integrate with other systems.\n",
    "# -   `Examples`:\n",
    "#     -   Email or calendar automation\n",
    "#     -   Task management (e.g., Todoist, Notion)\n",
    "#     -   Zapier or Make integrations\n",
    "\n",
    "# ### 8.  `Custom Domain-Specific Tools`\n",
    "\n",
    "# -   `Purpose`: Handle specialized tasks in specific industries.\n",
    "# -   `Examples`:\n",
    "#     -   Legal clause analyzers\n",
    "#     -   Medical symptom checkers\n",
    "#     -   Financial risk calculators\n",
    "\n",
    "# ### 9.  `Security and Access Tools`\n",
    "\n",
    "# -   `Purpose`: Manage authentication, authorization, and secure data access.\n",
    "# -   `Examples`:\n",
    "#     -   OAuth-based access control\n",
    "#     -   Role-based data filters\n",
    "#     -   Audit loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310811dd-b238-4174-9081-7bb96884b9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f0275-db28-442a-afeb-1089b12e8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## How LLMs Select Tools Based on Prompts\n",
    "\n",
    "# ### 1.  `Intent Recognition`\n",
    "\n",
    "# The LLM first analyzes the prompt to understand  `what the user is trying to do`.\n",
    "\n",
    "# -   `Example`:  \n",
    "#     Prompt:  _\"What’s the weather in Bangalore today?\"_  \n",
    "#     → Intent: Needs  `real-time data`  → Use  `Web Search Tool`\n",
    "\n",
    "# ### 2.  `Tool Matching Logic`\n",
    "\n",
    "# The system has a  `predefined list of tools`  and knows what each tool is capable of. It matches the prompt’s intent to the most appropriate tool.\n",
    "\n",
    "# ### 3.  `Trigger Conditions`\n",
    "\n",
    "# Some systems use  `rules or classifiers`  to decide when to trigger a tool. These can be:\n",
    "\n",
    "# -   `Keyword-based`  (e.g., \"plot\", \"calculate\", \"search\")\n",
    "# -   `Intent-based`  (using a classifier or another model)\n",
    "# -   `Context-aware`  (based on previous turns or memory)\n",
    "# - \n",
    "# ### 4.  `Tool Invocation`\n",
    "\n",
    "# Once a tool is selected:\n",
    "\n",
    "# -   The LLM  `formats a sub-prompt`  or  `API call`  for the tool.\n",
    "# -   The tool executes the task and returns the result.\n",
    "# -   The LLM  `integrates the result`  into its final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce1d10-9f20-4ca4-98cd-a29cd15bb921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1eaf44-b15b-4f57-b578-4bb7a34217c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Challenges with a Large Number of Tools\n",
    "\n",
    "# ### 1.  `Tool Selection Complexity`\n",
    "\n",
    "# -   The LLM must  `distinguish between many similar tools`.\n",
    "# -   It becomes harder to  `accurately match intent`  to the right tool.\n",
    "# -   Risk of  `tool overlap`  or  `confusion`  increases.\n",
    "\n",
    "# ### 2.  `Latency and Performance`\n",
    "\n",
    "# -   More tools mean more  `decision logic`  and potentially more  `tool loading time`.\n",
    "# -   If tools are checked sequentially, it can slow down response time.\n",
    "\n",
    "# ### 3.  `Maintenance Overhead`\n",
    "\n",
    "# -   Each tool may require updates, documentation, and testing.\n",
    "# -   Ensuring  `compatibility`  and  `error handling`  across tools becomes harder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52c856-aca1-4eab-9e6c-b1ac39882b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c40499d-0b8a-41f0-8b1d-ccfefbd5a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Solutions and Best Practices\n",
    "\n",
    "# ###  1.  `Tool Registry with Metadata`\n",
    "\n",
    "# \t- Maintain a structured registry of tools with:\n",
    "\n",
    "# \t\t-   `Name`\n",
    "# \t\t-   `Capabilities`\n",
    "# \t\t-   `Input schema`\n",
    "# \t\t-   `Trigger keywords or intents`\n",
    "\n",
    "# This helps the LLM or system  `filter and rank tools`  efficiently.\n",
    "\n",
    "# ###  2.  `Intent Classification`\n",
    "# \t- Use an  `intent classifier`  (ML model or rule-based) to narrow down tool categories before invoking the LLM.\n",
    "\n",
    "# ###  3.  `Hierarchical Tool Selection`\n",
    "# \t- Organize tools into  `categories`  (e.g., Search, Math, File, Image) and let the LLM first choose a category, then a specific tool.\n",
    "\n",
    "# ###  4.  `Function Calling with Schema Validation`\n",
    "# \t- Use structured function calling (like OpenAI’s  `function_call`) with  `JSON schemas`  to ensure the LLM selects and formats tool \n",
    "#     calls correctly.\n",
    "\n",
    "# ###  5.  `Tool Usage Feedback Loop`\n",
    "# \t- Track tool usage and success rates to  `improve selection logic`  over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95edcbdf-3ed8-476d-a55c-659ee06d5ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f477782-97cf-4076-820d-b6170d941e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### How MCP Helps with Tool Selection Challenges\n",
    "\n",
    "# 1.  `Too many tools`  \n",
    "#     `How`  – MCP organizes tools into structured, discoverable resources exposed by servers.\n",
    "    \n",
    "# 2.  `Tool selection logic`  \n",
    "#     `How`  – MCP allows LLMs to query available tools and select based on metadata, not just keywords.\n",
    "    \n",
    "# 3.  `Scalability`  \n",
    "#     `How`  – Tools are modular and exposed via MCP servers, which can be added or removed without changing the LLM.\n",
    "    \n",
    "# 4.  `Latency`  \n",
    "#     `How`  – MCP supports lightweight, local servers for fast access, and remote services when needed.\n",
    "    \n",
    "# 5.  `Security and access control`  \n",
    "#     `How`  – MCP includes best practices for secure access to local and remote resources.\n",
    "    \n",
    "# 6.  `Prompt overload`  \n",
    "#     `How`  – MCP supports prompt templates and context injection, reducing the need for long prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a33b7b-2099-41c9-9261-3792d098302d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847dabdf-31bc-4672-99ad-2ad465df5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Cases Where Users Build Custom Tools\n",
    "\n",
    "# ### 1.  `Domain-Specific Tasks`\n",
    "\n",
    "# -   `Why`: General-purpose tools may not handle specialized tasks well.\n",
    "# -   `Examples`:\n",
    "#     -   Legal document analyzer\n",
    "#     -   Medical symptom checker\n",
    "#     -   Financial portfolio evaluator\n",
    "\n",
    "\n",
    "# ### 2.  `Custom Data Access`\n",
    "\n",
    "# -   `Why`: Users need to query private or proprietary databases.\n",
    "# -   `Examples`:\n",
    "#     -   Internal CRM or ERP system connector\n",
    "#     -   SQL query builder for company databases\n",
    "#     -   API wrapper for custom business logic\n",
    "\n",
    "\n",
    "# ### 3.  `Advanced Computation or Visualization`\n",
    "\n",
    "# -   `Why`: LLMs can't natively perform complex math or generate plots.\n",
    "# -   `Examples`:\n",
    "#     -   Python-based data analysis tool\n",
    "#     -   Chart or graph generator\n",
    "#     -   Simulation engine for scientific models\n",
    "\n",
    "\n",
    "# ### 4.  `File and Document Processing`\n",
    "\n",
    "# -   `Why`: Users want to extract, summarize, or transform content from files.\n",
    "# -   `Examples`:\n",
    "#     -   PDF summarizer\n",
    "#     -   Excel data extractor\n",
    "#     -   Code documentation generator\n",
    "\n",
    "\n",
    "# ### 5.  `Real-Time or External Data Retrieval`\n",
    "\n",
    "# -   `Why`: LLMs need up-to-date or dynamic information.\n",
    "# -   `Examples`:\n",
    "#     -   Weather or stock market fetcher\n",
    "#     -   News aggregator\n",
    "#     -   Sports score retriever\n",
    "\n",
    "\n",
    "# ### 6.  `Workflow Automation`\n",
    "\n",
    "# -   `Why`: Users want to automate multi-step tasks.\n",
    "# -   `Examples`:\n",
    "#     -   Email drafting and sending tool\n",
    "#     -   Task manager integration\n",
    "#     -   Report generation pipeline\n",
    "\n",
    "\n",
    "# ### 7.  `Security and Access Control`\n",
    "\n",
    "# -   `Why`: Sensitive environments require controlled access.\n",
    "# -   `Examples`:\n",
    "#     -   Authentication-aware tools\n",
    "#     -   Role-based data access filters\n",
    "#     -   Audit logging wrappers\n",
    "\n",
    "\n",
    "# ### 8.  `Custom UI or Interaction Logic`\n",
    "\n",
    "# -   `Why`: Users want tailored interfaces or conversational flows.\n",
    "# -   `Examples`:\n",
    "#     -   Chatbot with guided prompts\n",
    "#     -   Form-filling assistant\n",
    "#     -   Interactive quiz or tutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397d81c-4873-44ea-b52a-0d7cb86423c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aedd607-8399-4056-8424-d5e36a5257ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Tools in Agents\n",
    "\n",
    "# ### ✅ Tools are:\n",
    "\n",
    "# -   `External functions or services`  the agent can use\n",
    "# -   Registered with the agent as  `capabilities`\n",
    "# -   Invoked by the agent when needed to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242ab35-26a4-4c91-823e-ef3db09e35e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e08e1d-57b8-4dd3-86cf-0c421b270b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Common Causes of Tool Connectivity Failure\n",
    "\n",
    "# 1.  `Network Issues`\n",
    "#     -   Tool is hosted remotely and the network is down or unstable.\n",
    "\n",
    "# 2.  `Tool Server Unavailable`\n",
    "#     -   The API or service is offline, overloaded, or misconfigured.\n",
    "\n",
    "# 3.  `Authentication Errors`\n",
    "#     -   Missing or expired API keys, tokens, or credentials.\n",
    "\n",
    "# 4.  `Timeouts`\n",
    "#     -   Tool takes too long to respond, exceeding the system’s timeout limit.\n",
    "\n",
    "# 5.  `Incorrect Tool Invocation`\n",
    "#     -   The LLM or agent passed the wrong arguments or used the wrong format.\n",
    "\n",
    "# 6.  `Tool Not Registered`    \n",
    "#     -   The tool was not properly loaded or exposed to the agent.\n",
    "\n",
    "# 7.  `Version Mismatch`    \n",
    "#     -   The tool’s interface changed but the agent is using an outdated schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860af10-27fa-41d4-884b-094b51a8d3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64a106-8bb6-4643-86a4-871485007fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## How to Handle Tool Failures\n",
    "\n",
    "# ### 1.  `Graceful Fallback`\n",
    "#     -   Provide a helpful message to the user\n",
    "#             > \"The tool I need to complete this task is currently unavailable. Would you like me to try a different approach?\"\n",
    "    \n",
    "# ### 2.  `Retry Logic`\n",
    "#     -   Automatically retry the tool call after a short delay (with limits).\n",
    "\n",
    "# ### 3.  `Error Logging`\n",
    "#     -   Log the failure details for debugging and monitoring.\n",
    "\n",
    "# ### 4.  `Tool Health Checks`\n",
    "#     -   Periodically ping tools to ensure they’re online and responsive.\n",
    "\n",
    "# ### 5.  `Alternative Tools`\n",
    "#     -   Use a backup tool or method if the primary one fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701199a-56e0-44d4-8e5c-c3958aac42a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34185c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "from utils import (get_model_openAI,get_model_groq,get_openAI_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0368231",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = read_json(\"keys.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62c98d-f606-49dd-a74b-d9adac8b608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the OpenAI chat model\n",
    "llm = get_model_openAI(model = \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd8a528-5bd4-4763-94b5-bee48e93c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "\n",
    "def multiply_numbers(x, y):\n",
    "    return x * y\n",
    "math_tool = Tool(\n",
    "    name=\"MultiplyNumbers\",\n",
    "    func=lambda inputs: multiply_numbers(*inputs),\n",
    "    description=\"Multiplies two numbers and returns the result.\"\n",
    ")\n",
    "\n",
    "# This tool can now be used by an agent or another LangChain component to perform calculations dynamically.\n",
    "\n",
    "# 'Agents' in LangChain are advanced components that enable AI models to decide when and how to use 'tools' dynamically. \n",
    "\n",
    "# Types of LangChain Agents\n",
    "    # Reactive Agents\n",
    "    #    - Select and execute tools based on user input without long-term memory.\n",
    "    # Conversational Agents\n",
    "    #    - Maintain memory of past interactions, improving responses over time.\n",
    "    # Planning Agents\n",
    "    #    -  Break down complex tasks into smaller steps and execute them sequentially.\n",
    "    # Custom Agents\n",
    "    #    - Designed for specific use cases, such as automating workflows or handling customer support. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee58e9-4107-4de0-9277-7653430304d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b57eb936-3f5e-4ee0-a84b-6d8ad7313b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to search for the latest news articles about AI in 2025 to find the most up-to-date information.\n",
      "Action: Search\n",
      "Action Input: \"latest news about AI in 2025\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mHere's a recap of some of our biggest AI updates from June, including more ways to search with AI Mode, a new way to share your NotebookLM ...\n",
      "Summary: Chinese tech giant Baidu has announced plans to make its next-generation artificial intelligence model, Ernie, open-source by June 30, ...\n",
      "Generative AI saw particularly strong momentum, attracting $33.9 billion globally in private investment—an 18.7% increase from 2023. AI business usage is also ...\n",
      "We hosted Google Marketing Live 2025, where we showed how we're building AI-powered tools across Search and YouTube for marketers to quickly ...\n",
      "In 2025, AI will evolve from a tool for work and home to an integral part of both. AI-powered agents will do more with greater autonomy and help simplify your ...\n",
      "May 28, 2025. OpenAI's latest LLM opens doors for China's AI startups · Alibaba. April 29, 2025 ... Related News. AI News. July 2, 2025. Study finds AI can slash ...\n",
      "According to the World Economic Forum's 2025 Future of Jobs report, nine million jobs are expected to be “displaced” by A.I. and other emergent ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe latest news articles provide a comprehensive overview of the advancements and developments in AI in 2025.\n",
      "Final Answer: Baidu announced plans to make its next-gen AI model open-source, generative AI attracted significant private investment, and AI is evolving to become an integral part of work and home life in 2025.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Baidu announced plans to make its next-gen AI model open-source, generative AI attracted significant private investment, and AI is evolving to become an integral part of work and home life in 2025.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.agents import Tool,initialize_agent, AgentType\n",
    "from langchain_community.tools.searchapi.tool import SearchApiAPIWrapper\n",
    "\n",
    "search = SearchApiAPIWrapper(searchapi_api_key= keys.get(\"Keys\").get(\"SEARCh_API_KEY\"))\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"Useful for answering questions about current events or general knowledge.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = agent.run(\"What's the latest news about AI in 2025?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02210f-379c-4578-a410-fa76f26ae1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dea8cc23-156f-493d-8e74-22302e73534d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can use the Calculator tool to find the square root of 256, and then use the Wikipedia tool to find out who discovered gravity.\n",
      "Action: Calculator\n",
      "Action Input: sqrt(256)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError evaluating expression: name 'sqrt' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that I need to use a different format to calculate the square root.\n",
      "Action: Calculator\n",
      "Action Input: 256^(0.5)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError evaluating expression: unsupported operand type(s) for ^: 'int' and 'float'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using the Wikipedia tool to find out who discovered gravity first, and then find the square root of 256 separately.\n",
      "Action: Wikipedia\n",
      "Action Input: Who discovered gravity?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn physics, gravity (from Latin  gravitas 'weight'), also known as gravitation or a gravitational interaction, is a fundamental interaction, a mutual attraction between all massive particles.\n",
      "The gravitational attraction between clouds of primordial hydrogen and clumps of dark matter in the early universe caused the hydrogen gas to coalesce, eventually condensing and fusing to form stars.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe Wikipedia search did not specifically answer who discovered gravity, so I will try to search for it again.\n",
      "Action: Wikipedia\n",
      "Action Input: Discovery of gravity\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe Gravity Discovery Centre and Observatory is a \"hands-on\" science education, astronomy, Aboriginal culture and tourist centre, situated on the site of the Gravity Precinct in bushland near Gingin, north of Perth, Western Australia. \n",
      "It is a not-for-profit interactive science education centre, operated by The Gravity Discovery Centre Foundation Board Inc.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that the Wikipedia search did not provide the information I needed. I will try to search for the square root of 256 using the Calculator tool again.\n",
      "Action: Calculator\n",
      "Action Input: sqrt(256)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError evaluating expression: name 'sqrt' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt looks like the Calculator tool is not recognizing the sqrt function. I will try a different approach to find the square root of 256.\n",
      "Action: Calculator\n",
      "Action Input: 256 ** 0.5\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe result of 256 ** 0.5 is 16.0.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know that the square root of 256 is 16.0. Although I was unable to find out who specifically discovered gravity through the Wikipedia tool, the most commonly known person credited with discovering gravity is Sir Isaac Newton.\n",
      "Final Answer: The square root of 256 is 16.0, and Sir Isaac Newton is commonly credited with discovering gravity.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final Answer:\n",
      " The square root of 256 is 16.0, and Sir Isaac Newton is commonly credited with discovering gravity.\n"
     ]
    }
   ],
   "source": [
    "# Custom Tool \n",
    "    # A custom implementation of the llm-math tool (for math evaluation)\n",
    "    # A custom implementation of the wikipedia tool (for fetching summaries)\n",
    "\n",
    "\n",
    "import os\n",
    "import wikipedia\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.tools import tool\n",
    "\n",
    "llm = get_model_openAI(model = \"gpt-3.5-turbo\")\n",
    "\n",
    "# -------------------------------\n",
    "# Custom Tool: Math Evaluator\n",
    "# -------------------------------\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluates a basic math expression.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"The result of {expression} is {result}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "# -------------------------------\n",
    "# Custom Tool: Wikipedia Search\n",
    "# -------------------------------\n",
    "@tool\n",
    "def wiki_search(query: str) -> str:\n",
    "    \"\"\"Searches Wikipedia and returns a summary of the topic.\"\"\"\n",
    "    try:\n",
    "        summary = wikipedia.summary(query, sentences=2)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching Wikipedia summary: {e}\"\n",
    "\n",
    "# -------------------------------\n",
    "# Initialize LLM and Agent\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=calculate,\n",
    "        name=\"Calculator\",\n",
    "        description=\"Evaluates basic math expressions like 'sqrt(256)' or '2 + 2'.\"\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=wiki_search,\n",
    "        name=\"Wikipedia\",\n",
    "        description=\"Searches Wikipedia and returns a short summary of a topic.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Run the Agent\n",
    "# -------------------------------\n",
    "query = \"What is the square root of 256, and who discovered gravity?\"\n",
    "response = agent.run(query)\n",
    "\n",
    "print(\"\\nFinal Answer:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a79d386-2289-4e4e-ae41-a9fd63f76b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c81ad6a7-a4f2-475e-b1c1-28e0ecaf8b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the weather in Bangalore and also calculate 15 * 3.\n",
      "Action: GetWeather\n",
      "Action Input: Bangalore\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe weather in Bangalore is sunny.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the weather information, now I need to calculate 15 * 3.\n",
      "Action: BasicCalculator\n",
      "Action Input: 15 * 3\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe result of '15 * 3' is 45.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the weather in Bangalore (sunny) and the result of 15 * 3 (45).\n",
      "Final Answer: The weather in Bangalore is sunny and 15 * 3 is 45.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The weather in Bangalore is sunny and 15 * 3 is 45.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = get_model_openAI(model = \"gpt-3.5-turbo\")\n",
    "\n",
    "# Define a simple function\n",
    "def get_weather(location: str) -> str:\n",
    "    return f\"The weather in {location} is sunny.\"\n",
    "\n",
    "# Wrap it as a Tool\n",
    "weather_tool = Tool(\n",
    "    name=\"GetWeather\",\n",
    "    func=get_weather,\n",
    "    description=\"Use this tool to get the weather for a given location.\"\n",
    ")\n",
    "\n",
    "# Initialize tools list\n",
    "tools = []\n",
    "\n",
    "# Append the tool\n",
    "tools.append(weather_tool)\n",
    "\n",
    "\n",
    "# Define another function\n",
    "def basic_calculator(expression: str) -> str:\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"The result of '{expression}' is {result}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {str(e)}\"\n",
    "\n",
    "# Wrap it as a Tool\n",
    "calculator_tool = Tool(\n",
    "    name=\"BasicCalculator\",\n",
    "    func=basic_calculator,\n",
    "    description=\"Use this tool to evaluate basic math expressions like '2 + 2' or '10 / 3'.\"\n",
    ")\n",
    "\n",
    "# Append the new tool\n",
    "tools.append(calculator_tool)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "# Example query to test the agent\n",
    "response = agent.run(\"What's the weather in Bangalore and what is 15 * 3?\")\n",
    "\n",
    "print(response)\n",
    "\n",
    "\n",
    "# tools list contains both:\n",
    "\n",
    "    # GetWeather – for weather info\n",
    "    # BasicCalculator – for evaluating math expressions\n",
    "\n",
    "# When to Use tools.append()\n",
    "    # When you're dynamically building a list of tools.\n",
    "    # When you want to conditionally add tools based on some logic.\n",
    "    # When you're modularizing your tool definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08485a50-b0bb-4898-ab9b-aecd152560a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7d014a3-6348-440b-acf7-e3f3ace757e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_Ln4autqyhqzZPhp4hTsV4x0E', 'function': {'arguments': '{\\n  \"a\": 119,\\n  \"b\": 8\\n}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 99, 'total_tokens': 120, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BooMUB7doHwj79v74oapQyqe3wRma', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--ad4c4ceb-98a5-4366-ad54-1e2a5c6c381a-0' tool_calls=[{'name': 'multiply', 'args': {'a': 119, 'b': 8}, 'id': 'call_Ln4autqyhqzZPhp4hTsV4x0E', 'type': 'tool_call'}] usage_metadata={'input_tokens': 99, 'output_tokens': 21, 'total_tokens': 120, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "llm = get_model_openAI(model=\"gpt-4\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "response = llm_with_tools.invoke(\n",
    "    \"Whats 119 times 8 minus 20. Don't do any math yourself, only use tools for math. Respect order of operations\")\n",
    "\n",
    "print(response)\n",
    "\n",
    "# Use bind_tools() when:\n",
    "\n",
    "    # You're working with LangChain Expression Language (LCEL).\n",
    "    # You want to integrate tools directly into the LLM's reasoning.\n",
    "    # You want to avoid using agents but still allow tool usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0340a8d-7c96-40f6-937b-9a752d456be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40ef611f-7538-4b18-99a0-450bb4ce4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 1, 'b': 1}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m2\u001b[0m\u001b[32;1m\u001b[1;3m2\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
    "\n",
    "# setup the tools\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def square(a) -> int:\n",
    "    \"\"\"Calculates the square of a number.\"\"\"\n",
    "    a = int(a)\n",
    "    return a * a\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are a mathematical assistant.\n",
    "        Use your tools to answer questions. If you do not have a tool to\n",
    "        answer the question, say so. \n",
    "\n",
    "        Return only the answers. e.g\n",
    "        Human: What is 1 + 1?\n",
    "        AI: 2\n",
    "        \"\"\"),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = get_model_openAI(model=\"gpt-4\")\n",
    "\n",
    "# setup the toolkit\n",
    "toolkit = [add, multiply, square]\n",
    "\n",
    "# Construct the OpenAI Tools agent\n",
    "agent = create_openai_tools_agent(llm, toolkit, prompt)\n",
    "\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=toolkit, verbose=True)\n",
    "\n",
    "result = agent_executor.invoke({\"input\": \"what is 1 + 1?\"})\n",
    "\n",
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09399af8-324a-4687-a88c-6f64f0870d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9355c646-e19b-406e-b7b9-d5a83d555a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Initialize the Wikipedia API Wrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "# Using the tool\n",
    "\n",
    "result = tool.run({\"query\": \"LangChain\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af3e39-d30d-4ce2-bd25-1621b8d39a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca9ab72e-2446-4f6a-b173-c2b03f972abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to look up the TV show Foundation on Wikipedia and then return the answer in all lower case.\n",
      "Action: Wikipedia\n",
      "Action Input: Foundation (TV series)\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mFoundation is an American science fiction television series created by David S. Goyer and Josh Friedman for Apple TV+, based on the Foundation series of stories by Isaac Asimov. It features an ensemble cast led by Jared Harris, Lee Pace, Lou Llobell and Leah Harvey.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the information about the show, but it is not in lower case.\n",
      "Action: lower_case\n",
      "Action Input: Foundation is an American science fiction television series created by David S. Goyer and Josh Friedman for Apple TV+, based on the Foundation series of stories by Isaac Asimov. It features an ensemble cast led by Jared Harris, Lee Pace, Lou Llobell and Leah Harvey.\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mfoundation is an american science fiction television series created by david s. goyer and josh friedman for apple tv+, based on the foundation series of stories by isaac asimov. it features an ensemble cast led by jared harris, lee pace, lou llobell and leah harvey.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'foundation is an american science fiction television series created by david s. goyer and josh friedman for apple tv+, based on the foundation series of stories by isaac asimov. it features an ensemble cast led by jared harris, lee pace, lou llobell and leah harvey.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(\"lower_case\", return_direct=True)\n",
    "def to_lower_case(input:str) -> str:\n",
    "  \"\"\"Returns the input as all lower case.\"\"\"\n",
    "  return input.lower()\n",
    "\n",
    "tools.append(to_lower_case)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\"What is the Apple TV show Foundation about? Return the answer in all lower case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72782b4c-1a43-4a4c-bcac-82f59f86ef89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0d29368-1bb8-4cef-add8-3583887e45ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe capital of Manitoba is a fact-based question and doesn't require up-to-date information or current events. I have this knowledge.\n",
      "Final Answer: The capital of Manitoba is Winnipeg.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Manitoba is Winnipeg.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Handling Errors\n",
    "\n",
    "from langchain.tools.base import ToolException\n",
    "\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "def _handle_error(error: ToolException) -> str:\n",
    "    return (\n",
    "        \"The following errors occurred during tool execution:\"\n",
    "        + error.args[0]\n",
    "        + \"Please try another tool.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def search_tool1(s: str):\n",
    "    raise ToolException(\"The search tool1 is not available.\")\n",
    "\n",
    "\n",
    "def search_tool2(s: str):\n",
    "    raise ToolException(\"The search tool2 is not available.\")\n",
    "\n",
    "\n",
    "search_tool3 = DuckDuckGoSearchRun()\n",
    "\n",
    "description = \"useful for when you need to answer questions about current events.You should give priority to using it.\"\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search_tool1,\n",
    "        name=\"Search_tool1\",\n",
    "        description=description,\n",
    "        handle_tool_error=True,\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=search_tool2,\n",
    "        name=\"Search_tool2\",\n",
    "        description=description,\n",
    "        handle_tool_error=_handle_error,\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=search_tool3.run,\n",
    "        name=\"Search_tool3\",\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent.run(\"What is the Capital of Manitoba?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc4f6a-89c0-4a4b-8bd4-3ffaebcf550e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4682de7-74c1-482d-a4b9-3a4a51f4624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.82\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculate_percentage_marks(marks_obtained: int, marks_total: int) -> float:\n",
    "  \"\"\"Calculate Percentage using Marks Obtained and Total Marks\"\"\"\n",
    "  percentage = (marks_obtained*100.0)/marks_total\n",
    "  percentage = round(percentage,2)\n",
    "  return percentage\n",
    "\n",
    "print(calculate_percentage_marks.invoke({\"marks_obtained\": 670,\n",
    "\"marks_total\": 850}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e0fcb3-9ed8-457b-9453-9a2f820463dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43dacfe7-d505-4f53-a710-f8b76501daac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.75, 4.2, 4.95]\n"
     ]
    }
   ],
   "source": [
    "# Using Pydantic BaseModel args_schema with @tool decorator:\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class IncreasePricesInput(BaseModel):\n",
    "  prices: List[float] = Field(description=\"List of prices to increase\")\n",
    "  increase_factor: float = Field(description=\"Factor by which to increase the prices\")\n",
    "\n",
    "@tool(args_schema=IncreasePricesInput)\n",
    "def increase_prices(prices: List[float], increase_factor: float) -> List[float]:\n",
    "  \"\"\"Increase a list of prices by multiplying them with an increase factor\"\"\"\n",
    "  return [round(price * increase_factor, 2) for price in prices]\n",
    "\n",
    "print(increase_prices.invoke({ \"prices\": [2.5,2.8,3.3], \"increase_factor\": 1.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38daab0-1b1a-4eab-8077-a71892f4cbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b594142d-98e5-43b2-bd04-c55f522c5133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `height_in_cm` with `{'feet': 5, 'inches': 9}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m175.26\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `height_in_cm` with `{'feet': 5, 'inches': 11}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m180.34\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `height_in_cm` with `{'feet': 5, 'inches': 10}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m177.8\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sort_numbers` with `{'numbers': [175.26, 180.34, 177.8]}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[175.26, 177.8, 180.34]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `find_median` with `{'numbers': [175.26, 177.8, 180.34]}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m177.8\u001b[0m\u001b[32;1m\u001b[1;3mThe heights of the boys in cm after sorting are 175.26 cm, 177.8 cm, and 180.34 cm. The median height of the boys is 177.8 cm.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class SortInput(BaseModel):\n",
    "  numbers: List[float] = Field(description=\"List of numbers to sorted\")\n",
    "\n",
    "@tool (args_schema=SortInput)\n",
    "def sort_numbers(numbers: List[float]) -> List[float]:\n",
    "  \"\"\"Sort a list of numbers\"\"\"\n",
    "  return sorted(numbers)\n",
    "\n",
    "class MedianInput(BaseModel):\n",
    "  numbers: List[float] = Field(description=\"List of numbers to median\")\n",
    "\n",
    "@tool (args_schema=MedianInput)\n",
    "def find_median(numbers: List[float]) -> float:\n",
    "  \"\"\"Find the Median of a list of numbers\"\"\"\n",
    "  med = np.median (numbers)\n",
    "  return round(med, 2)\n",
    "\n",
    "class HeightInput(BaseModel):\n",
    "  feet: int = Field(description=\"Height in feet\")\n",
    "  inches: int = Field(description=\"Height in inches\")\n",
    "\n",
    "@tool (args_schema = HeightInput)\n",
    "def height_in_cm(feet: int, inches: int) -> float:\n",
    "  \"\"\"Convert height in feet (ft) and inches (in) to centimeters (cm)\"\"\"\n",
    "  total_inches = feet * 12 + inches\n",
    "  cm = total_inches * 2.54\n",
    "  return round(cm, 2)\n",
    "\n",
    "tools = [sort_numbers,find_median,height_in_cm]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "  (\"system\",\n",
    "  \"You are a helpful assistant. Make sure to use the tools to do\\\n",
    "  the relevant conversions and calculation for getting information.\",\n",
    "  ),\n",
    "  (\"placeholder\", \"{chat_history}\"),\n",
    "  (\"human\", \"{input}\"),\n",
    "  (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "  ]\n",
    ")\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "input_prompt = \"\"\"Find the median height of Boys in cm considering the following information.\n",
    "Also write those cm heights of boys after sorting:\n",
    "The heights of girls were 5 ft 4 in, 5 ft 3 in and 5 ft 7 in.\n",
    "The heights of boys were 5 ft 9 in, 5 ft 11 in and 5 ft 10 in.\"\"\"\n",
    "\n",
    "res = agent_executor.invoke({\"input\": input_prompt})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b50e10-d10f-4cdf-85cc-caaa163b1d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c68e9dec-d9e6-4afe-83c8-daf69f9aa83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import List\n",
    "\n",
    "class CryptoCurrencySummary(BaseModel):\n",
    "    name: str\n",
    "    high: float\n",
    "    low: float\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    date: str = Field(description=\"date of yesterday with the format YYYY-MM-DD\")\n",
    "    crypto_currencies: List[CryptoCurrencySummary] = Field(description=\"list of 10 best cryptocurrencies summary of yesterday\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Summary)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "        You're an expert about cryptocurrency.\n",
    "        Your role is to extract yesterday's high and low about the 10 best cryptocurrencies.\n",
    "        The date format should be in the format YYYY-MM-DD\n",
    "                                \n",
    "        {format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "json = chain.invoke({})\n",
    "result = parser.parse(json.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a0aeb-d051-4fc4-ae3a-4cc976730ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
